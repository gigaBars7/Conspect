{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9001e5dd-7146-42e6-a3f5-622221339c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729281bc-ad94-4e21-bedf-60c08bf094d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 687, Val: 76\n",
      "path = /mnt/d/DataSets/whiteboard\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = Path(\"/mnt/d/DataSets/whiteboard\").resolve()\n",
    "val_size = 0.1\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "\n",
    "images_train = dataset_dir / \"images\" / \"train\"\n",
    "labels_train = dataset_dir / \"labels\" / \"train\"\n",
    "\n",
    "images_val = dataset_dir / \"images\" / \"val\"\n",
    "labels_val = dataset_dir / \"labels\" / \"val\"\n",
    "\n",
    "images_val.mkdir(parents=True, exist_ok=True)\n",
    "labels_val.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def flatten(dir_path: Path):\n",
    "    for sub in list(dir_path.iterdir()):\n",
    "        if sub.is_dir():\n",
    "            for f in sub.iterdir():\n",
    "                target = dir_path / f.name\n",
    "                if not target.exists():\n",
    "                    shutil.move(str(f), target)\n",
    "            sub.rmdir()\n",
    "\n",
    "\n",
    "flatten(images_train)\n",
    "flatten(labels_train)\n",
    "\n",
    "pairs = []\n",
    "for img in images_train.iterdir():\n",
    "    if img.suffix.lower() in {\".jpg\", \".jpeg\", \".png\"}:\n",
    "        lbl = labels_train / f\"{img.stem}.txt\"\n",
    "        if lbl.exists():\n",
    "            pairs.append((img, lbl))\n",
    "\n",
    "random.shuffle(pairs)\n",
    "val_count = int(len(pairs) * val_size)\n",
    "val_pairs = pairs[:val_count]\n",
    "\n",
    "for img, lbl in val_pairs:\n",
    "    shutil.move(img, images_val / img.name)\n",
    "    shutil.move(lbl, labels_val / lbl.name)\n",
    "\n",
    "data_yaml = dataset_dir / \"data.yaml\"\n",
    "\n",
    "with open(data_yaml, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = yaml.safe_load(f) or {}\n",
    "\n",
    "for k in [\"train\", \"val\", \"test\", \"path\"]:\n",
    "    data.pop(k, None)\n",
    "\n",
    "data[\"path\"] = str(dataset_dir)\n",
    "data[\"train\"] = \"images/train\"\n",
    "data[\"val\"] = \"images/val\"\n",
    "\n",
    "if isinstance(data.get(\"names\"), dict):\n",
    "    data[\"names\"] = [data[\"names\"][i] for i in sorted(data[\"names\"])]\n",
    "    data[\"nc\"] = len(data[\"names\"])\n",
    "\n",
    "with open(data_yaml, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump(data, f, allow_unicode=True, sort_keys=False)\n",
    "\n",
    "print(f\"Train: {len(pairs) - val_count}, Val: {val_count}\")\n",
    "print(f\"path = {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca1dfb-d707-4a0f-a501-2de7d45ba18d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
